{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/uk2051/CV_Project/SatelliteImagesSegmentation_Unet'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDir = '/scratch/uk2051/CV_Project/SatelliteImagesSegmentation_Unet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/uk2051/CV_Project/SatelliteImagesSegmentation_Unet/src\n"
     ]
    }
   ],
   "source": [
    "%cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/uk2051/CV_Project/SatelliteImagesSegmentation_Unet/src'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load cuda/11.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torch==1.12.1+cu116 in /home/uk2051/.local/lib/python3.8/site-packages (1.12.1+cu116)\n",
      "Requirement already satisfied: torchvision==0.13.1+cu116 in /home/uk2051/.local/lib/python3.8/site-packages (0.13.1+cu116)\n",
      "Requirement already satisfied: torchaudio==0.12.1 in /home/uk2051/.local/lib/python3.8/site-packages (0.12.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /home/uk2051/.local/lib/python3.8/site-packages (from torch==1.12.1+cu116) (4.4.0)\n",
      "Requirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision==0.13.1+cu116) (2.24.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision==0.13.1+cu116) (8.0.1)\n",
      "Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torchvision==0.13.1+cu116) (1.19.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu116) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu116) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu116) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu116) (2.10)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: argparse in /home/uk2051/.local/lib/python3.8/site-packages (1.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /home/uk2051/.local/lib/python3.8/site-packages (0.9.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: segmentation_models_pytorch in /home/uk2051/.local/lib/python3.8/site-packages (0.3.1)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /home/uk2051/.local/lib/python3.8/site-packages (from segmentation_models_pytorch) (0.7.4)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/uk2051/.local/lib/python3.8/site-packages (from segmentation_models_pytorch) (0.13.1+cu116)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /home/uk2051/.local/lib/python3.8/site-packages (from segmentation_models_pytorch) (0.7.1)\n",
      "Requirement already satisfied: timm==0.4.12 in /home/uk2051/.local/lib/python3.8/site-packages (from segmentation_models_pytorch) (0.4.12)\n",
      "Requirement already satisfied: tqdm in /home/uk2051/.local/lib/python3.8/site-packages (from segmentation_models_pytorch) (4.64.1)\n",
      "Requirement already satisfied: pillow in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from segmentation_models_pytorch) (8.0.1)\n",
      "Requirement already satisfied: torch in /home/uk2051/.local/lib/python3.8/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.12.1+cu116)\n",
      "Requirement already satisfied: munch in /home/uk2051/.local/lib/python3.8/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (2.5.0)\n",
      "Requirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.24.0)\n",
      "Requirement already satisfied: typing-extensions in /home/uk2051/.local/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (4.4.0)\n",
      "Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torchvision>=0.5.0->segmentation_models_pytorch) (1.19.2)\n",
      "Requirement already satisfied: six in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2020.6.20)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (1.19.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datetime in /home/uk2051/.local/lib/python3.8/site-packages (4.7)\n",
      "Requirement already satisfied: pytz in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from datetime) (2020.1)\n",
      "Requirement already satisfied: zope.interface in /home/uk2051/.local/lib/python3.8/site-packages (from datetime) (5.5.2)\n",
      "Requirement already satisfied: setuptools in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from zope.interface->datetime) (49.2.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in /home/uk2051/.local/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/uk2051/.local/lib/python3.8/site-packages (from torchmetrics) (1.12.1+cu116)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torchmetrics) (1.19.2)\n",
      "Requirement already satisfied: packaging in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchmetrics) (20.4)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.9\" in /home/uk2051/.local/lib/python3.8/site-packages (from torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: six in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from packaging->torchmetrics) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from packaging->torchmetrics) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: numpy>=1.15 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/uk2051/.local/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from opencv-python) (1.19.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip3 install argparse\n",
    "!pip3 install tabulate\n",
    "!pip3 install segmentation_models_pytorch\n",
    "!pip3 install numpy\n",
    "!pip3 install datetime\n",
    "!pip3 install torchmetrics\n",
    "!pip3 install matplotlib\n",
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import SegmentationDataset as sdata\n",
    "import SegmentationModel as sm\n",
    "import trainloop as segmentation_train_test\n",
    "import Visualizer as v\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/uk2051/CV_Project/SatelliteImagesSegmentation_Unet/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/uk2051/CV_Project/SatelliteImagesSegmentation_Unet\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/uk2051/CV_Project/SatelliteImagesSegmentation_Unet'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing all the arguments used by RunModel function:\n",
      "CUDA Availability:  True\n"
     ]
    }
   ],
   "source": [
    "workspaceRoot = os.getcwd()\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "lr = 5e-5\n",
    "\n",
    "print('Printing all the arguments used by RunModel function:')\n",
    "print('CUDA Availability: ', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data count when mode is train is: 7470\n",
      "Data count when mode is test is: 1602\n",
      "Data count when mode is val is: 1602\n"
     ]
    }
   ],
   "source": [
    "trainDataset = sdata.Landcover_ai_Dataset(workspaceRoot)\n",
    "train_dloader = DataLoader(trainDataset,batch_size = batch_size)\n",
    "visualizer = v.Visualizer(train_dloader,workspaceRoot)\n",
    "visualizer.VisualizeEightImages('training set')\n",
    "\n",
    "testDataset = sdata.Landcover_ai_Dataset(workspaceRoot, mode = \"test\")\n",
    "test_dloader = DataLoader(testDataset, batch_size = batch_size)\n",
    "visualizer = v.Visualizer(test_dloader,workspaceRoot)\n",
    "visualizer.VisualizeEightImages('testing set')\n",
    "\n",
    "\n",
    "validDataset = sdata.Landcover_ai_Dataset(workspaceRoot, mode = \"val\")\n",
    "val_dloader = DataLoader(validDataset, batch_size=batch_size,)\n",
    "visualizer = v.Visualizer(val_dloader,workspaceRoot)\n",
    "visualizer.VisualizeEightImages('validation set')\n",
    "visualizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Model\n",
    "segmentationModel =  sm.SegmentationModel(workspaceRoot)\n",
    "segmentationModel.InitializeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTestObj = segmentation_train_test.TrainTest(segmentationModel, train_dloader, val_dloader, test_dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 7            |        cudaMalloc retries: 7         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |     800 MB |   30878 MB |   77328 MB |   76527 MB |\\n|       from large pool |     781 MB |   30840 MB |   77276 MB |   76494 MB |\\n|       from small pool |      19 MB |      38 MB |      51 MB |      32 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |     800 MB |   30878 MB |   77328 MB |   76527 MB |\\n|       from large pool |     781 MB |   30840 MB |   77276 MB |   76494 MB |\\n|       from small pool |      19 MB |      38 MB |      51 MB |      32 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    6586 MB |   31118 MB |   32142 MB |   25556 MB |\\n|       from large pool |    6562 MB |   31078 MB |   32102 MB |   25540 MB |\\n|       from small pool |      24 MB |      40 MB |      40 MB |      16 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    5785 MB |    5803 MB |   24623 MB |   18838 MB |\\n|       from large pool |    5780 MB |    5798 MB |   24571 MB |   18791 MB |\\n|       from small pool |       4 MB |       6 MB |      51 MB |      46 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     343    |     903    |    1248    |     905    |\\n|       from large pool |      23    |     156    |     351    |     328    |\\n|       from small pool |     320    |     747    |     897    |     577    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     343    |     903    |    1248    |     905    |\\n|       from large pool |      23    |     156    |     351    |     328    |\\n|       from small pool |     320    |     747    |     897    |     577    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      28    |      99    |     100    |      72    |\\n|       from large pool |      16    |      79    |      80    |      64    |\\n|       from small pool |      12    |      20    |      20    |       8    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      31    |      84    |     270    |     239    |\\n|       from large pool |      26    |      27    |      83    |      57    |\\n|       from small pool |       5    |      60    |     187    |     182    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in 1.0 h 26.0 m 20.55 s.\n"
     ]
    }
   ],
   "source": [
    "trainTestObj.segmentation_training_loop(epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restting the leaning rate, since earlier one is too small\n",
    "#Trying again\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading existing model\n",
    "loadModelName = 'epoch-19_1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTestObj = segmentation_train_test.TrainTest(segmentationModel, train_dloader, val_dloader, test_dloader, loadModelName, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for eval\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "precision = torchmetrics.Precision(task = \"multiclass\", num_classes=5, average= None).to(trainTestObj.device)\n",
    "recall = torchmetrics.Recall(task = \"multiclass\", num_classes=5, average= None).to(trainTestObj.device)\n",
    "F1_score = torchmetrics.F1Score(task = \"multiclass\", num_classes=5, average= None).to(trainTestObj.device)\n",
    "acc = torchmetrics.Accuracy(num_classes = 5, average = \"micro\",task=\"multiclass\").to(trainTestObj.device)\n",
    "mlacc = torchmetrics.classification.MulticlassExactMatch(num_classes=5).to(trainTestObj.device)\n",
    "jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes = 5).to(trainTestObj.device)\n",
    "\n",
    "model = trainTestObj.model.to(trainTestObj.device)\n",
    "model.eval()\n",
    "\n",
    "class_probs = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
    "num_samples = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9fcd32445bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mclass_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtrainTestObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Background\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Building\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Woodland\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Water\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Road\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF1_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlacc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaccard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/uk2051/CV_Project/SatelliteImagesSegmentation_Unet/src/trainloop.py\u001b[0m in \u001b[0;36mclass_report\u001b[0;34m(self, classes, precision, recall, F1score, acc, mlacc, jaccard, class_probs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Background\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "for batch_index, (X,y) in enumerate(trainTestObj.test_loader):\n",
    "    X = X.to(trainTestObj.device)\n",
    "    y = y.to(trainTestObj.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = F.softmax(model(X), dim =1)\n",
    "        probs, preds = torch.max(logits, dim = 1)\n",
    "\n",
    "        for label in class_probs.keys():\n",
    "            class_probs[label]+= probs[preds == label].flatten().sum()\n",
    "            num_samples[label]+= preds[preds == label].flatten().size(dim = 0)\n",
    "\n",
    "        precision.update(preds, y)\n",
    "        recall.update(preds, y)\n",
    "        F1_score.update(preds, y)\n",
    "        acc.update(preds,y)\n",
    "        mlacc.update(preds,y)\n",
    "        jaccard.update(preds, y)\n",
    "\n",
    "    image = X\n",
    "    predicted_mask = preds\n",
    "    ground_truth = y\n",
    "    imageFileName = os.path.join(trainTestObj.visualizations_dir, \"Predictions_\" + str(batch_index))\n",
    "    batchImageName = imageFileName\n",
    "    num_images = image.shape[0]\n",
    "\n",
    "    for index in range(num_images):\n",
    "        img = image[index].cpu().numpy()\n",
    "        img = np.transpose(img, (1,2,0))\n",
    "        pred = predicted_mask[index].cpu().numpy()\n",
    "        gt = ground_truth[index].cpu().numpy()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 4), nrows=1, ncols=3)\n",
    "        ax[0].set_title('Statellite Image')\n",
    "        ax[0].imshow(img)\n",
    "\n",
    "\n",
    "        ax[1].set_title('Model prediction')\n",
    "        ax[1].imshow(pred)\n",
    "\n",
    "        ax[2].set_title('Ground Truth')\n",
    "        ax[2].imshow(gt)\n",
    "\n",
    "        title = 'Model Prediction'\n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.savefig(batchImageName +'_' + str(index))\n",
    "        plt.close(fig)\n",
    "    \n",
    "    for label in class_probs.keys():\n",
    "            class_probs[label] /= num_samples[label]\n",
    "\n",
    "    trainTestObj.class_report([\"Background\",\"Building\",\"Woodland\",\"Water\",\"Road\"], precision.compute(), recall.compute(), F1_score.compute(), acc.compute(), mlacc.compute(), jaccard.compute(), class_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Functions for eval\n",
    "\n",
    "\n",
    "        for batch_index, (X,y) in enumerate(self.test_loader):\n",
    "            X = X.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = F.softmax(model(X), dim =1)\n",
    "                probs, preds = torch.max(logits, dim = 1)\n",
    "\n",
    "                for label in class_probs.keys():\n",
    "                    class_probs[label]+= probs[preds == label].flatten().sum()\n",
    "                    num_samples[label]+= preds[preds == label].flatten().size(dim = 0)\n",
    "\n",
    "                precision.update(preds, y)\n",
    "                recall.update(preds, y)\n",
    "                F1_score.update(preds, y)\n",
    "                acc.update(preds,y)\n",
    "                mlacc.update(preds,y)\n",
    "                jaccard.update(preds, y)\n",
    "\n",
    "            imageFileName = os.path.join(self.visualizations_dir, \"Predictions_\" + str(batch_index))\n",
    "            VisualizePrediction(X, preds, y, imageFileName)\n",
    "        for label in class_probs.keys():\n",
    "            class_probs[label] /= num_samples[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
